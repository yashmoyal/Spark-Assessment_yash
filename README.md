# Spark-Assessment_yash
A Spark project using Databricks Delta Lake

# Spark Installation Process

# **this installation process assumes you already have the JDK 11 or above along with python latest version.

![Screenshot 2022-06-27 113645](https://user-images.githubusercontent.com/73746900/175870790-dc2afa6d-f84c-46d9-8088-32c89a19373f.jpg)
![Screenshot 2022-06-27 113614](https://user-images.githubusercontent.com/73746900/175870800-8a450c34-08dc-48ac-a39f-d23fb84ef0a3.jpg)

## Step 1: Go ahead to the Spark official Webstie and go to the downloads page ("https://spark.apache.org/downloads.html")
![Screenshot 2022-06-27 112833](https://user-images.githubusercontent.com/73746900/175869783-aa84eced-a7a7-421c-9319-1ec8f9565bc4.jpg)
## Step 2: Download the Specific Release tar file for installation ("For this project we use Spark 3.1.2")
![Screenshot![Screenshot 2022-06-27 112616](https://user-images.githubusercontent.com/73746900/175869643-ca64597e-4b21-4180-be37-8b86edb81b30.jpg)
## Step 3: After downloading Extract the tar file and setup the Environment variable for HADOOP_HOME, SPARK_HOME and path variable for bin folder.
![Screenshot 2022-06-27 113123](https://user-images.githubusercontent.com/73746900/175870119-18ac5d61-778e-4293-b718-875e39aff12a.jpg)
![Screenshot 2022-06-27 113150](https://user-images.githubusercontent.com/73746900/175870129-ad049776-8669-4395-a117-9f9e6369fa8b.jpg)
![Screenshot 2022-06-27 113211](https://user-images.githubusercontent.com/73746900/175870131-c8951de9-85a8-41a1-9239-9d0f433afc11.jpg)
## Step 4: Check if the spark is running fine in command prompt by entering the command "pyspark" for the python users and "spark-shell" for Scala users.
![Screenshot 2022-06-27 113408](https://user-images.githubusercontent.com/73746900/175870428-23285325-f3e1-48ee-8aeb-e75c9e0f4aab.jpg)
![Screenshot 2022-06-27 113446](https://user-images.githubusercontent.com/73746900/175870435-296cfd3e-2d1e-49ff-b44c-492dcb594a48.jpg)

## After that Install pyspark for Delta (for using Delta Lake in Spark)
(https://pypi.org/project/delta-spark/1.0.1/)

![Screenshot 2022-06-27 114149](https://user-images.githubusercontent.com/73746900/175871394-77c03289-6dad-4984-8e18-48bd84135932.jpg)

# Execution Instructuion

## for Executing the Project you have to use the code provided in the spark.ipynb file in this repository by importing the useful Libraries

# Additional Information

## Environment Used: Jupyter Notebook
## Libraries Used: Delta,pyspark

# Useful links: 

## Spark Standalone setup/installation
## o https://phoenixnap.com/kb/install-spark-on-windows-10
## o https://www.geeksforgeeks.org/install-apache-spark-in-a-standalone-mode-on-windows/
## o https://sparkbyexamples.com/spark/apache-spark-installation-on-windows/

## Delta Format Official Documentation

## https://docs.delta.io/latest/index.html

## Apache Spark official Documentation

## https://spark.apache.org/docs/latest/






